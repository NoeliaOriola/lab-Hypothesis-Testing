{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjI20x84zSx2"
   },
   "source": [
    "# Before you start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources (README.md file)\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzAOTQfoz15Q",
    "outputId": "9597f4c2-a277-4c68-a984-a22cd1d353c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/noelia.escobar/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - scipy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    scipy-1.11.4               |  py311hc76d9b0_0        21.1 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        21.1 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  scipy                              1.11.1-py311hc76d9b0_0 --> 1.11.4-py311hc76d9b0_0 \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIKv798RzSx6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvMX-v1TzSx7"
   },
   "source": [
    "# Challenge 1 - Exploring the Data\n",
    "\n",
    "In this challenge, we will examine all salaries of employees of the San Francisco. We will start by loading the dataset and examining its contents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jx8dpv-xzSx8",
    "outputId": "c1a35f3c-afb6-4b20-d774-06bbdca465ea"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Salaries.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28njElH1zSx9"
   },
   "source": [
    "Examine the `salaries` dataset using the `head` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "MtrTvrTMzSx9",
    "outputId": "0dae2341-f13f-4cbe-a9ee-93804e23d1c0"
   },
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78ppeI4czSx-"
   },
   "outputs": [],
   "source": [
    "#We see from looking at the `head` function that there is quite a bit of missing data. Get the amount of missing data in every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_count = data.isnull().sum()\n",
    "display(missing_data_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mqyrt17AzSx-",
    "outputId": "c0d862ff-8beb-417a-9b6e-2ae950c19492"
   },
   "outputs": [],
   "source": [
    "missing_percentage = (data.isnull().sum() / len(data) * 100).round(2)\n",
    "print(missing_percentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7_uHi3nzSx_"
   },
   "source": [
    "Get the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_cJvEdTgzSx_",
    "outputId": "61a90101-4466-42db-fc53-b2be109f586d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dvi-WtBNzSyA"
   },
   "source": [
    "Given output of the previous two cells, drop the corresponding column and compute again the amount of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns with a high percentage of missing values\n",
    "data_dropped = data.drop(['Notes', 'Status'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOynt6ZkzSyA",
    "outputId": "6e80e3ba-a79a-402d-e2be-996a8ab13c77"
   },
   "outputs": [],
   "source": [
    "# Computing the amount of missing values in the modified dataframe\n",
    "missing_data_after_drop = data_dropped.isnull().sum()\n",
    "\n",
    "print(\"Missing data after dropping columns:\")\n",
    "print(missing_data_after_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrIJFfY4zSyB"
   },
   "source": [
    "Check out what are the possible values of the column \"Status\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_status_values = data['Status'].unique()\n",
    "print(\"Unique values in the 'Status' column:\")\n",
    "print(unique_status_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-rUObH9zSyB",
    "outputId": "8d9b940d-694c-401b-8535-d390e829acdc"
   },
   "outputs": [],
   "source": [
    "#understanding PT for Part Time and FT for Full Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7c1YgwUzSyC"
   },
   "source": [
    "Drop any row with missing values in the \"Status\" column and compute again the number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with missing values in the 'Status' column\n",
    "data_dropped_status = data.dropna(subset=['Status'])\n",
    "\n",
    "# Computing the amount of missing values in the modified dataframe\n",
    "missing_data_after_drop_status = data_dropped_status.isnull().sum()\n",
    "\n",
    "print(\"Missing data after dropping rows with missing 'Status':\")\n",
    "print(missing_data_after_drop_status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNuimPv6zSyC"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZzzRW3ezSyC",
    "outputId": "719afa36-7982-4685-c606-195ea8e0f658"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxOUWb9AzSyD"
   },
   "source": [
    "Check out the types of each column and see if they make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYtPT0MJzSyD",
    "outputId": "7fc00b2a-b36b-4e0d-fc11-3b87e284ce92"
   },
   "outputs": [],
   "source": [
    "#We observe that numerical values, variables are as dtype object, we need to convert them in numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "8mJv_l6HzSyE",
    "outputId": "5dd1494c-537e-4a0b-c0c0-761ee64a00dd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLEKu7vxzSyE"
   },
   "source": [
    "Do any type conversions and reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "mf7huPFRzSyF",
    "outputId": "3d84ce08-71e7-4121-91ea-bc6e777d0b9f"
   },
   "outputs": [],
   "source": [
    "# Convert 'Year' column to datetime type\n",
    "data['Year'] = pd.to_datetime(data['Year'], format='%Y', errors='coerce')\n",
    "\n",
    "# Convert 'Benefits' column to numeric, replacing non-convertible values with NaN\n",
    "data['Benefits'] = pd.to_numeric(data['Benefits'], errors='coerce')\n",
    "\n",
    "# Reset the index\n",
    "data = data.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting relevant columns to numeric, replacing non-numeric values with NaN\n",
    "numeric_columns = ['BasePay', 'OvertimePay', 'OtherPay', 'Benefits', 'TotalPayBenefits']\n",
    "data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DNK_QLozSyF"
   },
   "source": [
    "Check out if \"TotalPayBenefits\" = \"BasePay\" + \"OvertimePay\" + \"OtherPay\" + \"Benefits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuydOtmBzSyF",
    "outputId": "83cd3939-89ec-4e36-dda8-ebb4b8e49013"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['CalculatedTotal'] = data[['BasePay', 'OvertimePay', 'OtherPay', 'Benefits']].sum(axis=1, skipna=True)\n",
    "\n",
    "# Check if \"TotalPayBenefits\" is close to the calculated sum\n",
    "data['CheckSum'] = np.isclose(data['TotalPayBenefits'], data['CalculatedTotal'])\n",
    "\n",
    "# Display rows where the sum doesn't match \"TotalPayBenefits\" excluding NaN values\n",
    "mismatched_rows = data[data['CheckSum'] == False]\n",
    "\n",
    "# Reset the index\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Display the result\n",
    "print(\"Rows where 'TotalPayBenefits' does not match the calculated sum (excluding NaN values):\")\n",
    "print(mismatched_rows[['TotalPayBenefits', 'BasePay', 'OvertimePay', 'OtherPay', 'Benefits']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65AtoiMDzSyF"
   },
   "source": [
    "What is the percetage of employees for which the previous assumption is not True?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of employees with a mismatch in the assumption\n",
    "percentage_mismatch = (mismatched_rows.shape[0] / data.shape[0]) * 100\n",
    "\n",
    "print(f\"Percentage of employees for whom the assumption is not true: {percentage_mismatch:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQSlyYKfzSyG",
    "outputId": "db98ca20-db17-4900-c441-896b1d3ae1de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxAKJ0grzSyG"
   },
   "source": [
    "There are different departments in the city. List all departments and the count of employees in each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting department information from JobTitle column using regular expression\n",
    "data['Department'] = data['JobTitle'].str.extract(r'\\((.*?)\\)')\n",
    "\n",
    "department_counts = data['Department'].value_counts()\n",
    "print(\"Department-wise employee counts:\")\n",
    "print(department_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "rIP5w8uqzSyG",
    "outputId": "792a6c68-1553-489f-b021-6a1f1eb2fc75",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBkEuDaLzSyG"
   },
   "source": [
    "# Challenge 2 - Hypothesis Tests\n",
    "\n",
    "In this section of the lab, we will test whether the hourly wage of **all FT workers is significantly different from $75/hr**. Get first the hourly wage by dividing \"TotalPayBenefits\" by 50 weeks (assuming 10 labour days of holidays) and by 40hrs (assuming a 40hrs week).\n",
    "\n",
    "$$Hourly Wage = \\frac{TotalPayBenefits}{1 year}\\frac{1 year}{50 Week}\\frac{1 Week}{40 hr}$$\n",
    "\n",
    "Import the correct one sample test function from scipy and perform the hypothesis test for a 95% two sided confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: (compute the \"Hourly_Wage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "ELuWVlkczSyH",
    "outputId": "1acd9c1f-b72c-475a-f1fe-f17450539be3"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Assuming 'TotalPayBenefits' contains the total pay and benefits\n",
    "data['Hourly_Wage'] = data['TotalPayBenefits'] / (50 * 40 * 10)\n",
    "\n",
    "# Specify the hypothesized mean hourly wage ($75/hr)\n",
    "hypothesized_mean = 75\n",
    "\n",
    "# Perform one-sample t-test\n",
    "t_stat, p_value = ttest_1samp(data['Hourly_Wage'].dropna(), hypothesized_mean)\n",
    "\n",
    "# Display the results\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Checking if the null hypothesis is rejected at a 95% confidence level\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The hourly wage is significantly different from $75/hr.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the hourly wage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: (Compute the mean hourly wage for all the \"FT\" employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZLcwczBzSyH",
    "outputId": "4f607da2-4d79-48cf-d176-f85c64df2848"
   },
   "outputs": [],
   "source": [
    "# Filtering data for full-time employees\n",
    "full_time_data = data[data['Status'] == 'FT']\n",
    "\n",
    "# Computing the mean hourly wage for full-time employees\n",
    "mean_hourly_wage_ft = full_time_data['Hourly_Wage'].mean()\n",
    "\n",
    "print(f\"Mean Hourly Wage for Full-Time Employees: {mean_hourly_wage_ft:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: (compute the t_statistic). Take into account that this dataset is a sample of a real population.\n",
    "# Remember that you only need to consider \"FT\" employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zTcooP57zSyH",
    "outputId": "55834a56-23e4-40f0-8e83-56a40e8eb268"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Filter data for full-time employees\n",
    "full_time_data = data[data['Status'] == 'FT']\n",
    "\n",
    "# Specify the hypothesized mean hourly wage ($75/hr)\n",
    "hypothesized_mean = 75\n",
    "\n",
    "# Perform one-sample t-test for full-time employees\n",
    "t_stat_ft, p_value_ft = ttest_1samp(full_time_data['Hourly_Wage'].dropna(), hypothesized_mean)\n",
    "\n",
    "print(f\"T-statistic for Full-Time Employees: {t_stat_ft:.2f}\")\n",
    "print(f\"P-value for Full-Time Employees: {p_value_ft:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Critical value. Get the critical value and compare it against your statisttic.\n",
    "# Your code here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uel9UMe2zSyH",
    "outputId": "34d5376a-3e12-49c4-a8e8-85210c27e96a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# Degrees of freedom (sample size - 1)\n",
    "degrees_of_freedom_ft = len(full_time_data['Hourly_Wage'].dropna()) - 1\n",
    "\n",
    "# Getting the critical value for a two-sided test\n",
    "critical_value = t.ppf(1 - alpha/2, degrees_of_freedom_ft)\n",
    "\n",
    "print(f\"Critical Value for Two-Sided Test: {critical_value:.2f}\")\n",
    "\n",
    "# Comparing with the t-statistic\n",
    "if abs(t_stat_ft) > critical_value:\n",
    "    print(\"Reject the null hypothesis: The mean hourly wage for Full-Time employees is significantly different from $75/hr.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the mean hourly wage for Full-Time employees.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Use the p-value method.\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4yteKjgzSyH",
    "outputId": "e78f6ef3-42c0-40f3-a24a-21f0d30ca56c"
   },
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "print(f\"P-value for Full-Time Employees: {p_value_ft:.4f}\")\n",
    "\n",
    "# Comparing with the significance level\n",
    "if p_value_ft <= alpha:\n",
    "    print(\"Reject the null hypothesis: The mean hourly wage for Full-Time employees is significantly different from $75/hr.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the mean hourly wage for Full-Time employees.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Use the ttest_1samp function from scipy. \n",
    "# Check the documentation [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html)\n",
    "# Make sure that you have a scipy version >=1.6.0. If that's not your case please ugrade your scipy version using\n",
    "# !pip install -U scipy\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIMw0PUqzSyI",
    "outputId": "6fbe4e5d-c9d8-473b-a64c-6c533bec9924"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# one-sample t-test for full-time employees\n",
    "t_stat_ft, p_value_ft = ttest_1samp(full_time_data['Hourly_Wage'].dropna(), hypothesized_mean)\n",
    "\n",
    "print(f\"P-value for Full-Time Employees: {p_value_ft:.4f}\")\n",
    "\n",
    "# Comparing with the significance level\n",
    "if p_value_ft <= alpha:\n",
    "    print(\"Reject the null hypothesis: The mean hourly wage for Full-Time employees is significantly different from $75/hr.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the mean hourly wage for Full-Time employees.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvxOReoszSyI"
   },
   "source": [
    "Are all the methods in agreement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6W3OpLYuzSyI"
   },
   "source": [
    "We are also curious about salaries in the police force. The chief of police in San Francisco claimed in a press briefing that salaries this year are **higher than last year's mean of $86000/year for all salaried employees** (use the column \"TotalPayBenefits\". Test  hypothesis using a 95% confidence interval.\n",
    "\n",
    "Hint: Use apply and a lambda function to check in \"Police\" is in the \"JobTitle\" to get all the \"Police\" jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: (compute the t_statistic). Take into account that this dataset is a sample of a real population.\n",
    "# Remember that you only need to consider \"Police\" employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZJ_pHiUzSyI",
    "outputId": "1b3fe9d9-2589-4afa-d7b0-4d09251a3ba3"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "police_data = data[data['JobTitle'].apply(lambda x: 'POLICE' in x.upper())]\n",
    "\n",
    "#one-sample t-test for police employees\n",
    "t_stat_police, p_value_police = ttest_1samp(police_data['TotalPayBenefits'].dropna(), 86000)\n",
    "\n",
    "print(f\"P-value for Police Employees: {p_value_police:.4f}\")\n",
    "\n",
    "if p_value_police <= alpha:\n",
    "    print(\"Reject the null hypothesis: Salaries in the police force are significantly higher than $86,000/year.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in salaries in the police force.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Critical value. Get the critical value and compare it against your statisttic.\n",
    "# Your code here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQec5gU6zSyJ",
    "outputId": "bc66c72a-9154-4a15-ca3a-6f59e30e1b1c"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# Degrees of freedom\n",
    "df = len(police_data) - 1\n",
    "\n",
    "# Critical value for a two-tailed test\n",
    "critical_value = t.ppf(1 - alpha/2, df)\n",
    "\n",
    "print(f\"Critical Value: {critical_value:.4f}\")\n",
    "\n",
    "# Comparing with the t-statistic\n",
    "if abs(t_stat_police) > critical_value:\n",
    "    print(\"Reject the null hypothesis: Salaries in the police force are significantly higher than $86,000/year.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in salaries in the police force.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Use the p-value method.\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVwWqhkOzSyJ",
    "outputId": "039b9c5f-b817-47ed-d4dc-686673241b9b"
   },
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "print(f\"P-value for Police Employees: {p_value_police:.4f}\")\n",
    "\n",
    "# Comparing with the significance level\n",
    "if p_value_police <= alpha:\n",
    "    print(\"Reject the null hypothesis: Salaries in the police force are significantly higher than $86,000/year.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in salaries in the police force.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Use the ttest_1samp function from scipy. \n",
    "# Check the documentation [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html)\n",
    "# Make sure that you have a scipy version >=1.6.0. If that's not your case please ugrade your scipy version using\n",
    "# !pip install -U scipy\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INGCUoXHzSyJ",
    "outputId": "0add2f05-e1c9-4a2c-c91d-731183b8463e"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "#one-sample t-test for police employees\n",
    "t_stat_police, p_value_police = ttest_1samp(police_data['TotalPayBenefits'].dropna(), 86000)\n",
    "\n",
    "print(f\"P-value for Police Employees: {p_value_police:.4f}\")\n",
    "\n",
    "# Comparing with the significance level\n",
    "if p_value_police <= alpha:\n",
    "    print(\"Reject the null hypothesis: Salaries in the police force are significantly higher than $86,000/year.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in salaries in the police force.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPCpi313zSyJ"
   },
   "source": [
    "The workers from the \"JobTitle\" with the most employees have complained that their hourly wage is **less than $35/hour**. Using a one sample t-test, test this one-sided hypothesis at the 95% confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: (Get the department which has most employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "m6X0DN4czSyJ",
    "outputId": "ed950bc6-1be7-4df6-be61-977bfb95d375"
   },
   "outputs": [],
   "source": [
    "# Finding the JobTitle with the most employees\n",
    "most_common_job = data['JobTitle'].mode().iloc[0]\n",
    "\n",
    "print(f\"JobTitle with the most employees: {most_common_job}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: (compute the t_statistic). Take into account that this dataset is a sample of a real population.\n",
    "# Remember that you only need to consider the right \"JobTitle\" employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifyDMFLXzSyJ",
    "outputId": "f350c751-9253-4140-a377-36c8112afc74"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "most_common_job_data = data[data['JobTitle'] == most_common_job]['TotalPayBenefits'].dropna()\n",
    "\n",
    "#one-sample t-test\n",
    "t_stat_most_common_job, p_value_most_common_job = ttest_1samp(most_common_job_data, 35)\n",
    "\n",
    "print(f\"P-value for {most_common_job} employees: {p_value_most_common_job:.4f}\")\n",
    "\n",
    "# Comparing with the significance level\n",
    "if p_value_most_common_job <= alpha:\n",
    "    print(f\"Reject the null hypothesis: Hourly wage for {most_common_job} employees is significantly less than $35/hour.\")\n",
    "else:\n",
    "    print(f\"Fail to reject the null hypothesis: There is no significant difference in hourly wage for {most_common_job} employees.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Critical value. Get the critical value and compare it against your statisttic.\n",
    "# Your code here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BCl3E2ItzSyK",
    "outputId": "f7677a30-0bf3-4c92-83f1-6a2e00f5176b"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "# Degrees of freedom\n",
    "df_most_common_job = len(most_common_job_data) - 1\n",
    "\n",
    "# Critical value for a one-sided test\n",
    "critical_value = t.ppf(1 - alpha, df_most_common_job)\n",
    "\n",
    "print(f\"Critical value: {critical_value:.4f}\")\n",
    "\n",
    "# Compare with the t-statistic\n",
    "if t_stat_most_common_job > critical_value:\n",
    "    print(f\"Reject the null hypothesis: Hourly wage for {most_common_job} employees is significantly less than $35/hour.\")\n",
    "else:\n",
    "    print(f\"Fail to reject the null hypothesis: There is no significant difference in hourly wage for {most_common_job} employees.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Use the p-value method.\n",
    "# Print the p-value\n",
    "print(f\"P-value for {most_common_job} employees: {p_value_most_common_job:.4f}\")\n",
    "\n",
    "# Comparing with the significance level\n",
    "if p_value_most_common_job <= alpha:\n",
    "    print(f\"Reject the null hypothesis: Hourly wage for {most_common_job} employees is significantly less than $35/hour.\")\n",
    "else:\n",
    "    print(f\"Fail to reject the null hypothesis: There is no significant difference in hourly wage for {most_common_job} employees.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EmIpVMd0zSyK",
    "outputId": "00cb8466-e885-4acb-9015-6d54b61b1c7d"
   },
   "outputs": [],
   "source": [
    "# Method 3: Use the ttest_1samp function from scipy. \n",
    "# Check the documentation [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html)\n",
    "# Make sure that you have a scipy version >=1.6.0. If that's not your case please ugrade your scipy version using\n",
    "# !pip install -U scipy\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lxmOkkIIzSyK",
    "outputId": "989799b7-3304-4954-e268-9b190515eb4b"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# one-sample t-test\n",
    "t_stat_most_common_job, p_value_most_common_job = ttest_1samp(most_common_job_data['Hourly_Wage'], 35)\n",
    "\n",
    "print(f\"t-statistic for {most_common_job} employees: {t_stat_most_common_job:.4f}\")\n",
    "print(f\"P-value for {most_common_job} employees: {p_value_most_common_job:.4f}\")\n",
    "\n",
    "# Comparing with the significance level\n",
    "if p_value_most_common_job <= alpha:\n",
    "    print(f\"Reject the null hypothesis: Hourly wage for {most_common_job} employees is significantly less than $35/hour.\")\n",
    "else:\n",
    "    print(f\"Fail to reject the null hypothesis: There is no significant difference in hourly wage for {most_common_job} employees.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNtFKSmuzSyK"
   },
   "source": [
    "# Challenge 3: To practice - Constructing Confidence Intervals\n",
    "\n",
    "While testing our hypothesis is a great way to gather empirical evidence for accepting or rejecting the hypothesis, another way to gather evidence is by creating a confidence interval. A confidence interval gives us information about the true mean of the population. So for a 95% confidence interval, we are 95% sure that the mean of the population is within the confidence interval. \n",
    ").\n",
    "\n",
    "To read more about confidence intervals, click [here](https://en.wikipedia.org/wiki/Confidence_interval).\n",
    "\n",
    "\n",
    "In the cell below, we will construct a 95% confidence interval for the mean hourly wage of all hourly workers. \n",
    "\n",
    "To compute the confidence interval of the hourly wage, use the 0.95 for the confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Get the critical values which correspond to a 95% confidence.\n",
    "from scipy.stats import t\n",
    "\n",
    "# Calculate the critical values\n",
    "df = len(hourly_wage_data) - 1  \n",
    "alpha = 0.05  \n",
    "\n",
    "# Getting the critical values from the t-distribution\n",
    "t_critical_left = t.ppf(alpha / 2, df)\n",
    "t_critical_right = t.ppf(1 - alpha / 2, df)\n",
    "\n",
    "\n",
    "print(f\"Critical value for the left tail: {t_critical_left:.4f}\")\n",
    "print(f\"Critical value for the right tail: {t_critical_right:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y78OZcg7zSyL",
    "outputId": "9e07b943-737e-4458-d47c-f093a174da98"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3FbLwVjzSyL"
   },
   "source": [
    "Now compute a 95% confidence interval for the hourly salary of all the Police employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "police_hourly_salary = data[data['JobTitle'].str.contains('Police', case=False)]['Hourly_Wage'].dropna()\n",
    "\n",
    "mean_hourly_salary = police_hourly_salary.mean()\n",
    "std_error_hourly_salary = np.std(police_hourly_salary, ddof=1) / np.sqrt(len(police_hourly_salary))\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = t_critical_right * std_error_hourly_salary\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval = (mean_hourly_salary - margin_of_error, mean_hourly_salary + margin_of_error)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean hourly salary for Police employees: ${mean_hourly_salary:.2f}\")\n",
    "print(f\"Margin of error: ${margin_of_error:.2f}\")\n",
    "print(f\"95% Confidence Interval: (${confidence_interval[0]:.2f}, ${confidence_interval[1]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJHkhMr6zSyL",
    "outputId": "9e39906c-f69b-462d-ebd4-af1dfcac014b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weFO_tpszSyL"
   },
   "source": [
    "# Chi2 test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfCTSUjSzSyL"
   },
   "source": [
    "Now we want to know if the amount of full time \"FT\" and part time \"PT\" employees is equal between Lawers, Meds, Police, Firemen and other departments. \n",
    "\n",
    "Considering all the options in this groups of employees will be very time consuming. To simplify this process, create first a function that returns:\n",
    "\n",
    "* \"Policemen\" if \"Police\" is found on \"JobTitle\"\n",
    "* \"Firemen\" if \"Fire\" is found on \"JobTitle\"\n",
    "* \"Medical\" if \"Med\" or \"Nurse\" is found on \"JobTitle\"\n",
    "* \"Lawyer\" if \"Attorney\" is found on \"JobTitle\"\n",
    "* \"Other\" in any other cases\n",
    "\n",
    "Then, create a new column named \"employee_group\" that determines to which group belong the employee. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZojYuxvazSyM"
   },
   "outputs": [],
   "source": [
    "def categorize_employee_group(job_title):\n",
    "    job_title = job_title.lower()\n",
    "\n",
    "    if 'police' in job_title:\n",
    "        return 'Policemen'\n",
    "    elif 'fire' in job_title:\n",
    "        return 'Firemen'\n",
    "    elif 'med' in job_title or 'nurse' in job_title:\n",
    "        return 'Medical'\n",
    "    elif 'attorney' in job_title:\n",
    "        return 'Lawyer'\n",
    "    else:\n",
    "        return 'Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new column 'employee_group'\n",
    "data['employee_group'] = data['JobTitle'].apply(categorize_employee_group)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "79H-XuKfzSyM",
    "outputId": "fa61544e-b697-478c-8227-88ce7cb6b965",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPCdBgKezSyM"
   },
   "source": [
    "Determine how many \"PT\" and \"FT\" employess have all the employees groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: (Store the output dataframe into a new variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "GB8tp2rDzSyM",
    "outputId": "b5a3ca3c-2300-4d37-ac9f-ca4b1cf80ceb"
   },
   "outputs": [],
   "source": [
    "# Count the number of \"PT\" and \"FT\" employees for each group\n",
    "employee_group_counts = data.groupby(['employee_group', 'Status']).size().unstack()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "employee_group_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJb-kx-7zSyM"
   },
   "source": [
    "Now try compute the expected frequencies doing the calculations with the individual probabilities. Remember that the Chi2 test assumes that both variables (employee_group and FT/PT) are not related (therefore they are independent). Therefore, to compute the expected frequencies you need to compute the probability of each cell and multiply it by the number of observations. ie:\n",
    "\n",
    "$$\\nu(x,y) = p(x,y) * N = p(x) * p(y) * N$$\n",
    "\n",
    "bear in mind that in general: $p(x,y)\\neq p(x)*p(y)$; the equality will only be true if x and y are independent. However, the null hypotheses says that **x and y are independent.** but that's what we're assuming with the null hypotheses.\n",
    "\n",
    "where \"x\" is the \"employee_group\" and \"y\" the (FT/PT). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe named \"frequencies\" to store the data.\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-fJvVuqzSyN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DataFrame to store expected frequencies\n",
    "frequencies = pd.DataFrame(index=['Policemen', 'Firemen', 'Medical', 'Lawyer', 'Other'], columns=['FT', 'PT'])\n",
    "\n",
    "# Display the empty DataFrame\n",
    "frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: Compute Expected frequency of being \"Firemen\" and \"FT\". Store the solution in a variable named \"firemen_ft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ld-NVuczSyN",
    "outputId": "8f4e0114-77c2-446b-f02f-bc5440b3fb9a"
   },
   "outputs": [],
   "source": [
    "p_firemen = frequencies.loc['Firemen'].sum() / total_observations\n",
    "\n",
    "p_ft = frequencies['FT'].sum() / total_observations\n",
    "\n",
    "firemen_ft = p_firemen * p_ft * total_observations\n",
    "\n",
    "firemen_ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: Compute Expected frequency of being \"Firemen\" and \"PT\". Store the solution in a variable named \"firemen_pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUp3VAXIzSyN",
    "outputId": "f20f5b9b-62fe-48b9-9638-a609464a0a06"
   },
   "outputs": [],
   "source": [
    "p_pt = frequencies['PT'].sum() / total_observations\n",
    "\n",
    "firemen_pt = p_firemen * p_pt * total_observations\n",
    "\n",
    "firemen_pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: Compute Expected frequency of being \"Lawyers\" and \"FT\". Store the solution in a variable named \"lawyers_ft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zTnWHxdzSyN",
    "outputId": "fa3db9aa-9fbb-482e-f35a-13fa9e605405"
   },
   "outputs": [],
   "source": [
    "p_ft = frequencies['FT'].sum() / total_observations\n",
    "\n",
    "lawyers_ft = p_lawyers * p_ft * total_observations\n",
    "\n",
    "lawyers_ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: Compute Expected frequency of being \"Lawyers\" and \"PT\". Store the solution in a variable named \"lawyers_pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_E2hWy7zSyN",
    "outputId": "0589a145-35fb-4441-c5e8-32bce904e01a"
   },
   "outputs": [],
   "source": [
    "p_pt = frequencies['PT'].sum() / total_observations\n",
    "\n",
    "lawyers_pt = p_lawyers * p_pt * total_observations\n",
    "\n",
    "lawyers_pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: Compute Expected frequency of being \"Medical\" and \"FT\". Store the solution in a variable named \"medical_ft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJSVxXMlzSyN",
    "outputId": "4731e0ca-028d-4582-fc75-772b2e3644b2"
   },
   "outputs": [],
   "source": [
    "p_ft = frequencies['FT'].sum() / total_observations\n",
    "\n",
    "medical_ft = p_medical * p_ft * total_observations\n",
    "\n",
    "medical_ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: Compute Expected frequency of being \"Medical\" and \"PT\". Store the solution in a variable named \"medical_pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: Compute Expected frequency of being \"Other\" and \"FT\". Store the solution in a variable named \"other_ft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: Compute Expected frequency of being \"Other\" and \"PT\". Store the solution in a variable named \"other_pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: Compute Expected frequency of being \"Policement\" and \"FT\". Store the solution in a variable named \"policemen_ft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: Compute Expected frequency of being \"Policement\" and \"PT\". Store the solution in a variable named \"policemen_pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRuFEP-WzSyO"
   },
   "source": [
    "* Store all the expected frequencies of \"FT\" employees in a list \n",
    "* Store all the \"PT\" employees into another list\n",
    "* Create a dictionary with \"FT\" and \"PT\" as keys and as the values use the previous lists\n",
    "* Create a dataframe with this dictionary using pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My notebook Kernel isn't laoding properly,it isn't running properly the functions above, therefore I can't add the calculating of expected frequency, can't complete at all the rest of the activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_list = [firemen_ft, lawyers_ft, medical_ft, other_ft, policemen_ft]\n",
    "pt_list = [firemen_pt, lawyers_pt, medical_pt, other_pt, policemen_pt]\n",
    "\n",
    "data_dict = {'FT': ft_list, 'PT': pt_list}\n",
    "\n",
    "expected_df = pd.DataFrame(data_dict, index=['Firemen', 'Lawyers', 'Medical', 'Other', 'Policemen'])\n",
    "\n",
    "print(expected_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "g6Otm4XUzSyO",
    "outputId": "7bbf7a53-e947-4137-8f03-35fb3b9cc3ee"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "serVGf6HzSyP"
   },
   "source": [
    "Now use the \"st.chi2_contingency()\" from scipy.stats [documentation here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) to conduct a Chi2 test to determine if the diferences between employee groups are statistically significant using a 95% confidence level. Hint: fill the function with a dataframe of actual frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: (use the st.chi2_contingency() function from scipy.stats to compute:\n",
    "# The Chi2 value\n",
    "# The p-valueYea we \n",
    "# The expected frequencies.\n",
    "# Ho: there is no relationship\n",
    "# Ha: there is relationship differences\n",
    "# p_value = P(table | Ho) = P(table | no relationship) = 1.51e-6 < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJ4eZt7UzSyP",
    "outputId": "8c3e8264-fa84-4046-b582-09283ac78611"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "chi2_stat, p_value, dof, expected_df = st.chi2_contingency\n",
    "\n",
    "print(f\"Chi2 Statistic: {chi2_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAlxWZjOzSyP"
   },
   "source": [
    "Check if your expected frequencies aggree with the ones obtained with the st.chi2_contingency() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbQbrku9zSyP"
   },
   "outputs": [],
   "source": [
    "print(\"Manual Expected Frequencies:\")\n",
    "print(expected_df)\n",
    "\n",
    "print(\"Expected Frequencies from chi2_contingency:\")\n",
    "print(expected)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "main_solutions.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
